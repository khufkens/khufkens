---
title: "Burn the candle at both ends"
subtitle: "the current state of academic publishing"
date: "2023-12-12"
categories: [academia, publishing]
draft: false
image: "featured.jpg"
image-alt: "Photo by Modestas Urbonas on Unsplash"
---

![Photo by Paul Melki on Unsplash](featured.jpg){.preview-image}

Academic researchers are being squeezed from both ends by publishers. This is by design. 

Not so long ago Cory Doctorow pitched the word "enshitification" for the state of the internet, and in particular the rise and ultimate decline of (tech) platforms. Per Doctorow, "platforms are firms which mediate between end users and business customers". In the scorching video at DEFCON31 Doctorow picks apart the decline of these entities, or why they will fold.

<center><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/rimtaSgGz_4?si=_GDnlEOprv8fjhyJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></center>

Where Uber connects drivers with riders and Amazon connects buyers with sellers. Where first a platform is good to its users, which will then draw business customers. Finally, when both are locked-in, for a lack of alternatives and entrenched patterns, the platform will bring down the hammer on both (extracting all value from both customers and business alike). But, although both users and businesses using the platforms will be robbed they mostly represent separate entities (e.g. drivers and riders of an Uber taxi).

### Academic publishing as a platform

Now, in the [effective oligopoly market](https://scholarlykitchen.sspnet.org/2023/10/30/quantifying-consolidation-in-the-scholarly-journals-market/) of academic publishing platforms this is driven to a peak as users and business customers are the same people, only separated by time in their research workflow. Researchers read, "consume", academic literature, where at the end of their research workflow they are in the business of "producing" new academic literature. The academic publishing platform only mediates between the same group of people separated by time - squeezing them at both ends. This process can only be described as a highly lucrative scam.

> Overall, the market has significantly consolidated since 2000 â€” when the top 5 publishers held 39% of the market of articles to 2022 where they control 61% of it. Looking at larger sets of publishers makes the consolidation even more extreme, as the top 10 largest publishers went from 47% of the market in 2000 to 75% in 2023, and the top 20 largest publishers from 54% to controlling 83% of the corpus. - [The Scholary Kitchen](https://scholarlykitchen.sspnet.org/2023/10/30/quantifying-consolidation-in-the-scholarly-journals-market/)

The drive for ever higher returns, [reaching up to 30% (with some estimates even higher)](https://www.nature.com/articles/495426a) and exceeding most tech platforms, puts an extreme burden on researchers and funding agencies. Where the proposed shift towards open access should have resolved some of the woes of accessibility in research, it only has boosted the further enshitification of academic publishing. Publishers actively double dip with mixed "open access" articles in otherwise closed access journals. This requires libraries or individual researches to still pay for journal subscriptions, with only those articles made open by the wealthy.

Increasingly, those same users and business customers are squeezed in other places of the value chain as well. Review times get shorter, paper mills and vacuous "special issues" and the active manipulation of researchers due to social media and other tokens (e.g. AltMetrics and Publons) make research and publishing harder. At the same time, additional value is extracted from the IP signed away and the consolidation of most of the academic workflow in other domains (citation management, data brokerage etc).

### A way out of enshitification

One has to question, when will this system break? Currently what gets published [outpaces the admission of new PhDs](https://fediscience.org/@MarkHanson/111147239095599059). One can argue that the vast amounts of research published today is either fake or only there to boost someone's h-index, not the creative enterprise which is science. Sadly, most efforts to address this [strong-link problem](https://www.experimental-history.com/p/science-is-a-strong-link-problem) are on the weak and wrong end of the problem. Listing all predatory journals doesn't make the good (society) journals stand out more.

A true measure of excellence would require a contextual analysis of scientific research, not only counting citations. Where the creation of Large Language Models might further pollute academic publishing the underlying Natural Language Processing (NLP) methods could offer solutions to provide contextual analysis. But here metrics might soon become the target once more, rather than a means of fair assessment.

The low tech option would be for researchers to step back and demonstrate [academic humility](https://www.nature.com/articles/d41586-023-03063-w). We need to return to slow, i.e. deliberate and creative scientific research, by abandoning the [Red Queen logic](https://totalinternalreflectionblog.com/2023/10/29/a-riposte-to-the-red-queens/) of a publishing treadmill leading nowhere. Excellence should not merely be measured by popularity, but by the quality of the work delivered, the dialogue it opened up, the service it provided to the scientific community or the public, and the long term value of it.