[
  {
    "objectID": "posts/on-brittle-code-code-debt-and-how-to-avoid-it/index.html",
    "href": "posts/on-brittle-code-code-debt-and-how-to-avoid-it/index.html",
    "title": "Brittle code",
    "section": "",
    "text": "Photo by Paul Melki on Unsplash\nBrittle code is code which is hard to maintain and or change. Large projects with brittle code accrue a technological / code debt. Depending on the size of the debt this debt will never be fully repaid, and if it escalates will grind a project to a halt.\nBrittle code and code debt is most commonly gathered over time due to a focus on features rather than a focus on maintainability and stability. An initial focus on features is common in growth phases, but consolidation and maintainability should be implemented before widespread use (commercially or privately in a lab setting). These are some tips to avoid brittle code."
  },
  {
    "objectID": "posts/on-brittle-code-code-debt-and-how-to-avoid-it/index.html#avoiding-brittle-code",
    "href": "posts/on-brittle-code-code-debt-and-how-to-avoid-it/index.html#avoiding-brittle-code",
    "title": "Brittle code",
    "section": "Avoiding brittle code",
    "text": "Avoiding brittle code\nBrittle code is hard to maintain code. A number of factors affect the maintainability of codebases.\n\ndependencies\nThe more dependencies code has the more likely it will break. This situation is critically illustrated by the cartoon below. By extension, never build code on immature external codebases. Maturing code is prone to ad-hoc changes, depreciation of features etc. Keep track of your dependencies!\nsize vs. functionality\nThe larger a codebase the harder it is to maintain, the larger the code debt it carries. Keep projects as large as the basic functionality requires. Extra functionality should reside in a new codebase. Large projects can be split up, but again this comes at a large code debt. It is best to not let a codebase grow beyond its basic use.\ndocumentation\nDocument code while you write it, this includes annotations but also formal documentation for users. Putting off writing the documentation and its framework until last will increase your code debt. For formal releases and well documented code consider that up to 50% of your time will be dedicated to documenting user and developer documentation.\nYes, this seems tedious and not necessary at the time, and it isn’t as sexy as implementing that new feature. BUT, if you return to old code and can’t figure out what is going on by reading along you will gather more code debt than it would have cost you to document things up front.\nunit tests\nTogether with documentation unit tests should be written. This validates the functioning of the code, and ensures that any pull requests submitted works as intended. Failing to do so will increase the code debt of a project, if not that of a colleagues by forwarding issues downstream.\nbranches should be short lived\nBranches should be short lived and have one particular focus. Stale branches should be deleted. Side development is probably best done in a forked version independent of the main project. Again, long lived branches will gather many functions. These new functions if out of sync with the main branch will create conflicts with other ongoing development. This will generated failed unit tests, and a general brittle state of the codebase. Branch, fix, merge. If a branch is older than two weeks it should probably been a fork (i.e. experimental features - or formal research project, or the assigned taskset is too large - split it up).\ncode for the reader\nCode for the reader of the code. Compiled code (packages) ignores comments. There is no need to be clever and “short”. Comment what you do in front of chunks (not in chunks as this will overrun line length constraints and give all kinds of compilation issues). Avoid one-liners (nested / piped functions), in this regard the R {tidyverse} and its piped setup can quickly become painful in terms of readability, as it violates this rule. Use the R {tidyverse} sparingly with short piped sections, as it is hard to read / debug with longer constructs.\npersonal & team responsibility\nAs a team you decide to keep code debt low. You don’t have the right to break a code base with the expectation that someone else on the team will fix it (see unit tests above)."
  },
  {
    "objectID": "posts/lost-inner-voices-llm-impact-problem-solving-chatgpt-ml-teaching/index.html",
    "href": "posts/lost-inner-voices-llm-impact-problem-solving-chatgpt-ml-teaching/index.html",
    "title": "Lost inner voices",
    "section": "",
    "text": "The Simpsons, Old Man and the Key\n\n\nOver the past years I’ve seen a steady decline in the problem solving ability of students. I fear large language models (LLMs), such as ChatGPT, might not do them a favour.\nNow, this might sound like an opinion of an “old man yells at cloud”. Google (search) and calculators were also once proposed to cause brain rot. But this cuts even deeper.\nMost people have some form of intrapersonal communication or inner-dialogue(s). Forms of self-talk underpin a lot of higher decision making such as self-control, self-direction but also problem solving skills. This self-talk can be positive, or negative, despite it being potentially valuable and insightful as written down by the cult classic “Zen and the Art of Motorcycle Maintenance” by Robert M. Pirsig. However, it remains largely a personal inner dialogue.\nBut, not anymore I would argue. A surprisingly large group of people have long and winding conversations with LLMs or have AI girlfriends. One can see the sadness that ensues if these LLMs start replacing friendly phone calls, because LLMs are more convenient to talk to as always available and uniquely tuned to your character. But what about our inner-dialogues?\n\noutsourcing your inner-dialogue\nI think that at least some of us might be in danger of replacing their inner-dialogue with commercial for profit chat bots. These chat bots could make their internal conversation external. Surfacing your self-talk was previously the domain of psychologists or psychiatrists, this is now done under little supervision at times with deadly consequences.\nEven without dramatic consequences, erosion of internal self-critical thought seems innocent but isn’t. Students, well everybody really, need critical problem solving skills. These problem solving skills are eroding fast, on a very basic level running deeper than Google search or calculators, while being supercharged for others.\nFor those who consciously use these LLMs, being careful on how to deploy them, might actually increase their self-critical skills as it gives them that additional external perspective previously conjured by rubber duck debugging, a Socratic (dialectic) method to problem solving. Much of this technology will further entrench social inequity, between those who unconsciously see their inner-voices replaced by commercial entities (for now without ads), and those that know how to game/use the system and mostly pay for quick access, privacy and an ad-free experience.\nI fear teaching critical problem solving skills will become more and more challenging in the years to come.\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{hufkens2023,\n  author = {Hufkens, Koen},\n  title = {Lost Inner Voices},\n  date = {2023-11-05},\n  url = {https://khufkens.com/posts/lost-inner-voices-llm-impact-problem-solving-chatgpt-ml-teaching},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nHufkens, Koen. 2023. “Lost Inner Voices.” November 5, 2023.\nhttps://khufkens.com/posts/lost-inner-voices-llm-impact-problem-solving-chatgpt-ml-teaching."
  },
  {
    "objectID": "posts/restarting-blog/index.html",
    "href": "posts/restarting-blog/index.html",
    "title": "Fresh start",
    "section": "",
    "text": "Photo by Jonas Allert on Unsplash\n\n\nI was unsure if I would take up personal blogging again. But, a recent Mastodon post by Carl T. Bergstrom made me realize the value of continuing after refactoring the website.\nWe are quickly going down the road of total enshitification of the web, due to the convincing nature of Large Language Model (LLM) output (think ChatGPT, Bard etc). The web will soon be filled with reams of auto-generated text not worth reading. To give you some context on where we are headed. Ever look up a recipe online these days? Notice how you had to scroll past pages of text on the life story of the author and why this recipe matters to them, while all you wanted was an ingredients list, food prep instructions and maybe a picture of how pasta puttanesca should look? This will be the web going forward, but EVERYWHERE. Finding trusted sources of information and worthwhile content to read will therefore come at a premium.\nI will therefore counter the enshitification of the web, by a handful of platforms, using the approach that made them big, i.e. by linking out.\n\n“It was perhaps the best encapsulation of a mantra I first heard from web pioneer Dave Winer: The more you send people away, the more they come back.” - Philip Bump (Musk is nearly done destroying what made Twitter twitter - Washington Post)\n\nAs such, I’ll pivot my old blog to a link blog with commentary and suggested reading links. This resonates with some of the comments I got from friends on some of the reading material I forward. This will also allow me to structure some of my thoughts and keep track of this content myself (as finding it again will increasingly be impossible).\nThis pivot also serves as a warning. Being a trusted source will become more important than ever. The importance of real life references and quality of the material written or linked to rather than “influencer” presence will dominate again (after a decade of cheap viral content and personalities who ride on it). It never really went away, as life is politics and connection, but for a brief moment one could get away with just being famous online.\n\nTo those landing here looking for old resources on the old blog: most of these have been integrated in packages and or tutorials currently reported on the BlueGreen Labs website or github page. If you find yourself searching for an old post, following a dead link, please consider looking there for answers.\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{hufkens2023,\n  author = {Hufkens, Koen},\n  title = {Fresh Start},\n  date = {2023-10-02},\n  url = {https://khufkens.com/posts/restarting-blog},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nHufkens, Koen. 2023. “Fresh Start.” October 2, 2023. https://khufkens.com/posts/restarting-blog."
  },
  {
    "objectID": "posts/swift-research-open-science/index.html",
    "href": "posts/swift-research-open-science/index.html",
    "title": "On swifts and open science",
    "section": "",
    "text": "Photo by Robert Booth\n\n\nThe past week some recent work on swift behaviour got published in The Proceedings of the Royal Society B. In this research I, together with a splendid team, discuss the influence of moonlight on flight behaviour and foraging tactics during the non-breeding season (across Africa) of three European swift species. This works follows on previous work in Oikos along the same research lines and by the same team, but led by Lyndon Kearsley, discussing the influence of atmospheric convergence zones on flight behaviour. Combined, these two studies provide an insight into how swifts optimize their behaviour to their flight environment, let it be wind and/or light.\nThis ornithology research grew out of the passion of Lyndon Kearsley who, as a long-term amateur ornithologist (50+ years), contributes to academic research on a regular basis but rarely as research lead. During the COVID pandemic he shared some of this passion with me, from which grew the plan to publish some of the insights which came from these discussions and subsequent conversations with other collaborators.\nPublishing science from the perspective of a small independent lab is certainly not open, as in easily accessible to all, even if ideas are good, the execution of the analysis spot-on, and the data and code openly available. I’m happy with the progress this team makes, but our largely unaffiliated status does not make our work easier. I think the scientific community, despite “broader impacts”, needs to acknowledge and consider outside contributions more seriously. Many fields still struggle with issues surrounding data ownership, proper attribution (of amateurs and citizen scientists), neo-colonialism and helicopter science and a publishing system which is increasingly financially out of reach for smaller labs.\nAcademic research can be decidedly competitive - chasing a vacuous Red Queen status quo. But, to end in a positive note, in these swift studies we took an explicit community based approach. BlueGreen Labs, through myself and Lyndon, tries to facilitate slower and open science by building knowledge, software, hardware, and a community surrounding all these aspects. We consciously stepped away from the Red Queen rat race of academic publishing, where we try to partner with diverse collaborators (co-authors) on a basis of a shared passion, expertise and trust.\nI think our work reflects the fact that one does not necessarily need a large budget to do impactful and fun science, for all involved. Research needs (interdisciplinary) community, foundation frameworks (among others in good software and hardware stacks and support/teaching), and open and honest communication with less careerism and one-upmanship. To end with a platitude: “If you want to go fast, go alone, if you want to go far, go together”.\n\n\nReferences\nHufkens, K. et al. (2023), Evaluating the effects of moonlight on the vertical flight profiles of three western palaearctic swifts. Royal Society. doi: https://doi.org/10.1098/rspb.2023.0957.\nKearsley, L. et al. (2022), The aeroecology of atmospheric convergence zones: the case of pallid swifts. Oikos, 2022: e08594. doi: https://doi.org/10.1111/oik.08594\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{hufkens2023,\n  author = {Hufkens, Koen},\n  title = {On Swifts and Open Science},\n  date = {2023-11-04},\n  url = {https://khufkens.com/posts/swift-research-open-science},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nHufkens, Koen. 2023. “On Swifts and Open Science.” November\n4, 2023. https://khufkens.com/posts/swift-research-open-science."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "As an earth system scientist and ecologist I model ecosystem processes. For more information on my scientific work I refer to BlueGreen Labs.\nHere you will find my reading, writing and some observations on work, life, science and academia."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Brittle code\n\n\ncode debt and how to avoid it\n\n\n4 min\n\n\n\nKoen Hufkens\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBurn the candle at both ends\n\n\nthe current state of academic publishing\n\n\n4 min\n\n\n\nKoen Hufkens\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLost inner voices\n\n\nthe LLM impact on problem-solving\n\n\n2 min\n\n\n\nKoen Hufkens\n\n\nNov 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn swifts and open science\n\n\nhard won battles in ornithology\n\n\n3 min\n\n\n\nKoen Hufkens\n\n\nNov 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTorch/Keras in R\n\n\nthe ecosystem moves forward\n\n\n2 min\n\n\n\nKoen Hufkens\n\n\nOct 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to draw an owl\n\n\nwise advice from an internet meme\n\n\n3 min\n\n\n\nKoen Hufkens\n\n\nOct 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding bridges\n\n\ngetting to distant places easily\n\n\n2 min\n\n\n\nKoen Hufkens\n\n\nOct 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFresh start\n\n\na new look - fresh content\n\n\n3 min\n\n\n\nKoen Hufkens\n\n\nOct 2, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/building-bridges-science-management/index.html",
    "href": "posts/building-bridges-science-management/index.html",
    "title": "Building bridges",
    "section": "",
    "text": "Photo by Modestas Urbonas on Unsplash\n\n\nThis is a quick post of some advice I gave about career development to an early career scientist. Take from it what you want.\n\nTry to build bridges between where you are and where you want to go (this can include people, places, topics, techniques).\nTouching on building, try to build (multiple) things (lines of research, data, code) which outlast singular projects or span several. This is why I’m relentless on using templates and formalizing code. This allows you to recycle old projects in a new context fast, so you can pivot into a new project quicker.\nDiversify your portfolio, don’t get painted into a corner. By definition ecology is interdisciplinary and chances are that you will have to do fieldwork / lab work at some point. Getting experience before you need to supervise people doing so (without any true experience) is key. Use early career years to make mistakes which in a management setting would be unforgivable (as affecting other people’s career - even more than your own).\nBuild bridges for other people! The bigger your responsibility (older you are) the more you have the ability to pay it forward (give people opportunities). You shouldn’t cannibalize your own work, but sometimes it is as easy as sending a simple email in support (or letting someone tag along or contribute). Do so!\n\nBuild bridges between people, build frameworks (foundations) to work from / upon, build diversity in your skills / interests / people and if possible encourage, and support, others to do the same.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{hufkens2023,\n  author = {Hufkens, Koen},\n  title = {Building Bridges},\n  date = {2023-10-10},\n  url = {https://khufkens.com/posts/building-bridges-science-management},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nHufkens, Koen. 2023. “Building Bridges.” October 10, 2023.\nhttps://khufkens.com/posts/building-bridges-science-management."
  },
  {
    "objectID": "posts/how-to-draw-an-owl-advice-from-a-meme/index.html",
    "href": "posts/how-to-draw-an-owl-advice-from-a-meme/index.html",
    "title": "How to draw an owl",
    "section": "",
    "text": "Much of project planning resolves around taking an idea, i.e. the badly drawn concept, to a fully detailed drawing (of an owl). However, both images at the beginning only live in your head. The initial idea, and the ideal outcome are separated by what is truly feasible. Most projects fail when they do not account for the practical difference between what it takes to manifest the idea and realize the ideal solution."
  },
  {
    "objectID": "posts/how-to-draw-an-owl-advice-from-a-meme/index.html#the-process-often-matters-most",
    "href": "posts/how-to-draw-an-owl-advice-from-a-meme/index.html#the-process-often-matters-most",
    "title": "How to draw an owl",
    "section": "The process (often) matters most",
    "text": "The process (often) matters most\nGiven that no project is free of setbacks of all sorts, it is key to realize that most of the project will be spent not focusing on the final details of the ideal image. Most time will be spent on figuring out ways how to even start drawing (the damn owl). A failure to account for the process and a singular focus on the ideal will run any project into the ground, from a resource or human perspective (causing undue stress).\n[Important note: in some projects there is no room for outright failure, but even high risk projects get revisions!]"
  },
  {
    "objectID": "posts/how-to-draw-an-owl-advice-from-a-meme/index.html#keep-track-of-projects",
    "href": "posts/how-to-draw-an-owl-advice-from-a-meme/index.html#keep-track-of-projects",
    "title": "How to draw an owl",
    "section": "Keep track of projects",
    "text": "Keep track of projects\nGiven that the project process is more important than the outcome it is key to keep track of progress, more precisely:\n\nwhy you took certain decisions?\nwhat went wrong, and how you resolved it (so others don’t have to repeat this mistake)?\ntrack the physical constraints of an implementation (for Machine Learning this could be GPUs used)?\ntrack limits on scalability (are processes easily parallelizable)?\ndocumentation, documentation, more documentation…\n\nDocument all these things extensively and show where value was added despite setbacks."
  },
  {
    "objectID": "posts/how-to-draw-an-owl-advice-from-a-meme/index.html#failing-forward",
    "href": "posts/how-to-draw-an-owl-advice-from-a-meme/index.html#failing-forward",
    "title": "How to draw an owl",
    "section": "Failing forward",
    "text": "Failing forward\nNobody likes to bring bad news, but if your project does not manage to draw (the owl) results finding added value in other aspects of a project is key. This does not only cover lessons learned (as listed above), but also covers proposing ways out of the impasse more generally. You can fail forward by pointing out why things didn’t work out the way it should have happened, but more so, how these issues can be resolved and avoided (and at what cost) in the future.\nWhere possible generate added value by providing small tangible products during the project. To continue the owl analogy, you might not be able to draw the fully detailed owl, but you might have put together a method to draw a very nice cartoon owl. This, on its own, has a certain value. Discarding this result because it did not meet the ideal would be foolish."
  },
  {
    "objectID": "posts/machine-learning-torch-R-luz/index.html",
    "href": "posts/machine-learning-torch-R-luz/index.html",
    "title": "Torch/Keras in R",
    "section": "",
    "text": "Photo by British Library on Unsplash\n\n\nRecently, I more formally picked up machine learning again - in a more day-to-day fashion rather than one-off projects. Specifically, I’m trying to use R within the context of deep learning. Given that the dominant ecosystem for machine learning mostly remains python this might come as a surprise.\nThing is, I don’t like pivoting in and out of environments. In particular, data wrangling is much easier in R than in python. Given that a good amount of machine learning is dealing with cleaning data and data wrangling it often seems a better fit to use R rather than python (with the exception being image processing).\nAnyway, I tried such a deep dive a couple of years ago with the excellent book “Deep Learning with R” by Francois Cholet. Sadly, at the time, the R ecosystem of Keras felt very brittle and incomplete. But, revisiting Keras, and Torch, again after a couple of years was a breath of fresh air. The R APIs feel more feature complete and in line with the python one.\nThe last couple of days I’ve really enjoyed the combination of {torch} and {luz} to model ecosystem flux data and phenology. Some key resources have been the Posit.io (rstudio) machine learning blog - which reblogs some of the work in the “Deep Learning and Scientific Computing with R torch” by Sigrid Keydana. Given that the first book by Francois Cholet was brilliant, I assume the second version is better with the increasing ability of TensorFlow and the Keras APIs. Pick up either of these books to get a good handle on machine learning in R. Depending on if and where I find time, I might blog about some tips and tricks.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{hufkens2023,\n  author = {Hufkens, Koen},\n  title = {Torch/Keras in {R}},\n  date = {2023-10-30},\n  url = {https://khufkens.com/posts/machine-learning-torch-R-luz},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nHufkens, Koen. 2023. “Torch/Keras in R.” October 30, 2023.\nhttps://khufkens.com/posts/machine-learning-torch-R-luz."
  },
  {
    "objectID": "posts/enshitification-of-academic-publishing/index.html",
    "href": "posts/enshitification-of-academic-publishing/index.html",
    "title": "Burn the candle at both ends",
    "section": "",
    "text": "Photo by Paul Melki on Unsplash\n\n\nAcademic researchers are being squeezed from both ends by publishers. This is by design.\nNot so long ago Cory Doctorow pitched the word “enshitification” for the state of the internet, and in particular the rise and ultimate decline of (tech) platforms. Per Doctorow, “platforms are firms which mediate between end users and business customers”. In the scorching video at DEFCON31 Doctorow picks apart the decline of these entities, or why they will fold.\n\n\n\n\nWhere Uber connects drivers with riders and Amazon connects buyers with sellers. Where first a platform is good to its users, which will then draw business customers. Finally, when both are locked-in, for a lack of alternatives and entrenched patterns, the platform will bring down the hammer on both (extracting all value from both customers and business alike). But, although both users and businesses using the platforms will be robbed they mostly represent separate entities (e.g. drivers and riders of an Uber taxi).\n\nAcademic publishing as a platform\nNow, in the effective oligopoly market of academic publishing platforms this is driven to a peak as users and business customers are the same people, only separated by time in their research workflow. Researchers read, “consume”, academic literature, where at the end of their research workflow they are in the business of “producing” new academic literature. The academic publishing platform only mediates between the same group of people separated by time - squeezing them at both ends. This process can only be described as a highly lucrative scam.\n\nOverall, the market has significantly consolidated since 2000 — when the top 5 publishers held 39% of the market of articles to 2022 where they control 61% of it. Looking at larger sets of publishers makes the consolidation even more extreme, as the top 10 largest publishers went from 47% of the market in 2000 to 75% in 2023, and the top 20 largest publishers from 54% to controlling 83% of the corpus. - The Scholary Kitchen\n\nThe drive for ever higher returns, reaching up to 30% (with some estimates even higher) and exceeding most tech platforms, puts an extreme burden on researchers and funding agencies. Where the proposed shift towards open access should have resolved some of the woes of accessibility in research, it only has boosted the further enshitification of academic publishing. Publishers actively double dip with mixed “open access” articles in otherwise closed access journals. This requires libraries or individual researches to still pay for journal subscriptions, with only those articles made open by the wealthy.\nIncreasingly, those same users and business customers are squeezed in other places of the value chain as well. Review times get shorter, paper mills and vacuous “special issues” and the active manipulation of researchers due to social media and other tokens (e.g. AltMetrics and Publons) make research and publishing harder. At the same time, additional value is extracted from the IP signed away and the consolidation of most of the academic workflow in other domains (citation management, data brokerage etc).\n\n\nA way out of enshitification\nOne has to question, when will this system break? Currently what gets published outpaces the admission of new PhDs. One can argue that the vast amounts of research published today is either fake or only there to boost someone’s h-index, not the creative enterprise which is science. Sadly, most efforts to address this strong-link problem are on the weak and wrong end of the problem. Listing all predatory journals doesn’t make the good (society) journals stand out more.\nA true measure of excellence would require a contextual analysis of scientific research, not only counting citations. Where the creation of Large Language Models might further pollute academic publishing the underlying Natural Language Processing (NLP) methods could offer solutions to provide contextual analysis. But here metrics might soon become the target once more, rather than a means of fair assessment.\nThe low tech option would be for researchers to step back and demonstrate academic humility. We need to return to slow, i.e. deliberate and creative scientific research, by abandoning the Red Queen logic of a publishing treadmill leading nowhere. Excellence should not merely be measured by popularity, but by the quality of the work delivered, the dialogue it opened up, the service it provided to the scientific community or the public, and the long term value of it.\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{hufkens2023,\n  author = {Hufkens, Koen},\n  title = {Burn the Candle at Both Ends},\n  date = {2023-12-12},\n  url = {https://khufkens.com/posts/enshitification-of-academic-publishing},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nHufkens, Koen. 2023. “Burn the Candle at Both Ends.”\nDecember 12, 2023. https://khufkens.com/posts/enshitification-of-academic-publishing."
  }
]